---
description: System architecture documentation for Project Leroy bird watching system
alwaysApply: true
tags:
  - architecture
  - system-design
  - raspberry-pi
  - edge-ai
  - project-leroy
---

# Project Leroy - System Architecture

## Overview

Project Leroy is a continuous bird detection and classification system running on Raspberry Pi. It operates in multiple phases: real-time detection (continuous service), periodic classification (cron job), and visitation processing (cron job). The system uses edge AI accelerators for efficient on-device inference.

---

## Hardware Architecture

### System (Raspberry Pi 5 + AI Kit)

```
┌─────────────────────────────────────────┐
│         Raspberry Pi 5                  │
│  ┌──────────────────────────────────┐  │
│  │  CPU: ARMv8, 2.4GHz quad-core    │  │
│  │  RAM: 4GB/8GB LPDDR4X            │  │
│  │  USB: 3.0 (5 Gbps) + USB 2.0     │  │
│  │  PCIe 2.0: For AI Kit             │  │
│  └──────────────────────────────────┘  │
│              │                         │
│              │ PCIe 2.0 (M.2 HAT+)     │
│              ▼                         │
│  ┌──────────────────────────────────┐  │
│  │  Raspberry Pi AI Kit              │  │
│  │  Hailo-8L AI Accelerator          │  │
│  │  Performance: ~13 TOPS            │  │
│  │  Interface: PCIe 2.0 (native)    │  │
│  └──────────────────────────────────┘  │
│              │                         │
│              │ Camera Interface         │
│              ▼                         │
│  ┌──────────────────────────────────┐  │
│  │  Raspberry Pi HQ Camera         │  │
│  │  Resolution: Up to 4K            │  │
│  └──────────────────────────────────┘  │
└─────────────────────────────────────────┘
```

**Key Features:**
- **Performance**: ARMv8 CPU, 13 TOPS AI accelerator
- **Integration**: Native PCIe 2.0 connection via M.2 HAT+
- **Memory**: 4GB/8GB RAM for batch processing
- **Official Tools**: Raspberry Pi provides official SDKs and tools for AI Kit

---

## Software Architecture

### Technology Stack

#### Software Stack
- **OS**: Raspberry Pi OS (Bookworm or later)
- **Python**: 3.11+
- **AI Framework**:
  - **Raspberry Pi Official Tools**: `rpicam-apps` (updated for AI Kit)
  - **Hailo SDK**: Official Raspberry Pi/Hailo integration
  - **Hailo Dataflow Compiler (DFC)**: For model conversion
- **Computer Vision**: `opencv-contrib-python` (updated)
- **Image Processing**: `numpy`, `pillow`, `imutils`
- **System Management**: `systemd` (service), `cron` (scheduled tasks)

**Important**: Always prefer Raspberry Pi's official tools and SDKs for AI Kit integration.

---

## System Architecture Overview

```
┌─────────────────────────────────────────────────────────────┐
│                    Raspberry Pi System                      │
│                                                              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Phase 1: Detection (Continuous Service)            │  │
│  │  ┌────────────────────────────────────────────────┐  │  │
│  │  │  systemd: leroy.service                        │  │  │
│  │  │  ┌──────────────────────────────────────────┐  │  │  │
│  │  │  │  leroy.py (or leroy-edgetpu.py)          │  │  │  │
│  │  │  │  - Camera capture (OpenCV)                │  │  │  │
│  │  │  │  - Frame preprocessing                     │  │  │  │
│  │  │  │  - Detection model inference              │  │  │  │
│  │  │  │  - Visitation tracking                     │  │  │  │
│  │  │  │  - Photo capture (boxed + full)           │  │  │  │
│  │  │  │  - Storage: storage/detected/             │  │  │  │
│  │  │  └──────────────────────────────────────────┘  │  │  │
│  │  └────────────────────────────────────────────────┘  │  │
│  └──────────────────────────────────────────────────────┘  │
│                                                              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Phase 2: Classification (Cron Job - Periodic)      │  │
│  │  ┌────────────────────────────────────────────────┐  │  │
│  │  │  cron: classify.sh                             │  │  │
│  │  │  ┌──────────────────────────────────────────┐  │  │  │
│  │  │  │  1. Stop leroy.service                   │  │  │  │
│  │  │  │  2. classify.py                          │  │  │  │
│  │  │  │     - Load classification model          │  │  │  │
│  │  │  │     - Process boxed images                │  │  │  │
│  │  │  │     - Add species + score to filename    │  │  │  │
│  │  │  │     - Move to /var/www/html/classified/ │  │  │  │
│  │  │  │  3. visitation.py                        │  │  │  │
│  │  │  │     - Process classified images           │  │  │  │
│  │  │  │     - Group by visitation_id             │  │  │  │
│  │  │  │     - Calculate best photos              │  │  │  │
│  │  │  │     - Generate visitations.json          │  │  │  │
│  │  │  │  4. Start leroy.service                  │  │  │  │
│  │  │  └──────────────────────────────────────────┘  │  │  │
│  │  └────────────────────────────────────────────────┘  │  │
│  └──────────────────────────────────────────────────────┘  │
│                                                              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Phase 3: Web Interface (Nginx)                        │  │
│  │  ┌────────────────────────────────────────────────┐  │  │
│  │  │  /var/www/html/                                │  │  │
│  │  │  - classified/{date}/{visitation_id}/         │  │  │
│  │  │  - visitations.json                            │  │  │
│  │  │  - React frontend (web/build/)                 │  │  │
│  │  └────────────────────────────────────────────────┘  │  │
│  └──────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

---

## Service Architecture

### Systemd Service Configuration

**File**: `service/leroy.service`

```ini
[Unit]
Description=Leroy Bird Detection Service
After=multi-user.target

[Service]
Type=idle
WorkingDirectory=/home/leroy/Projects/project-leroy
ExecStart=/home/leroy/Projects/project-leroy/run.sh
Restart=on-abort
User=leroy
Environment=DISPLAY=:0

[Install]
WantedBy=multi-user.target
```

**Service Lifecycle:**
1. **Start**: On system boot (after multi-user.target)
2. **Run**: Continuously captures frames, detects birds, tracks visitations
3. **Restart**: On abort/failure (automatic recovery)
4. **Stop**: Manually or by cron job for classification phase

### Service Script: `run.sh`

```bash
#!/bin/bash
git pull origin master
sudo cp -a web/build/. /var/www/html/
sleep 1
./leroy.py
```

**Responsibilities:**
- Update code from git repository
- Deploy web interface to Nginx directory
- Start detection service (`leroy.py`)

---

## Cron Job Workflow

### Classification Phase: `classify.sh`

**Scheduled**: Typically runs periodically (e.g., every hour or daily)

```bash
#!/bin/bash
# 1. Stop detection service
sudo systemctl stop leroy.service
sleep 1

# 2. Classify detected images
python3 classify.py --dir=storage/detected

# 3. Process visitations
DATE=$(date +'%Y-%m-%d')
sudo python3 visitation.py --dir=/var/www/html/classified --date=${DATE}

# 4. Restart detection service
sudo systemctl start leroy.service
```

**Why Stop Service?**
- Classification model uses the same AI accelerator
- Prevents resource conflicts
- Ensures clean state for classification

**Phase Breakdown:**

#### Step 1: Stop Detection Service
- Gracefully stops `leroy.service`
- Ensures no new detections during classification
- Prevents file system conflicts

#### Step 2: Classification (`classify.py`)
- Processes all images in `storage/detected/`
- Runs classification model on "boxed" images
- Adds species name and confidence score to filename
- Moves classified images to `/var/www/html/classified/`
- Moves "full" images to same directory structure

#### Step 3: Visitation Processing (`visitation.py`)
- Groups images by `visitation_id`
- Calculates best photo per visitation (clarity + scores)
- Determines species (most common classification)
- Generates `visitations.json` for web interface

#### Step 4: Restart Detection Service
- Resumes continuous detection
- System returns to Phase 1

---

## Data Flow

### Detection Phase Flow

```
Camera
  │
  ▼
OpenCV VideoCapture
  │
  ▼
Frame Preprocessing (resize to 500px width)
  │
  ▼
Detection Model Inference (EdgeTPU/Hailo)
  │
  ▼
Object Detection Results (bbox, score, class)
  │
  ▼
Visitation Tracking (visitations.py)
  │
  ├─► New Visitation? → Create visitation_id
  │
  └─► Bird Detected? → Capture Photos
      │
      ├─► Boxed Photo (cropped bbox + padding)
      │   └─► storage/detected/{date}/{visitation_id}/
      │       └─► boxed_{timestamp}_{score}.png
      │
      └─► Full Photo (entire frame)
          └─► storage/detected/{date}/{visitation_id}/
              └─► full_{timestamp}_{score}.png
```

### Classification Phase Flow

```
storage/detected/{date}/{visitation_id}/
  │
  ├─► boxed_{timestamp}_{score}.png
  │   │
  │   ▼
  │   Classification Model Inference
  │   │
  │   ▼
  │   Species + Classification Score
  │   │
  │   ▼
  │   Rename: boxed_{timestamp}_{score}_{species}_{class_score}.png
  │   │
  │   ▼
  │   /var/www/html/classified/{date}/{visitation_id}/
  │
  └─► full_{timestamp}_{score}.png
      │
      ▼
      /var/www/html/classified/{date}/{visitation_id}/
```

### Visitation Processing Flow

```
/var/www/html/classified/{date}/{visitation_id}/
  │
  ▼
Group by visitation_id
  │
  ▼
For each visitation:
  ├─► Calculate duration (first → last detection)
  ├─► Determine species (most common classification)
  ├─► Find best photo (clarity + detection + classification scores)
  ├─► Link full image
  └─► Create visitation record
      │
      ▼
visitations.json
  │
  ▼
Web Interface (React)
```

---

## Storage Structure

### Directory Hierarchy

```
project-leroy/
├── storage/
│   ├── detected/                    # Raw detection output
│   │   └── {YYYY-MM-DD}/           # Date-based organization
│   │       └── {visitation_id}/     # Visitation-based grouping
│   │           ├── boxed_{HH-MM-SS}_{score}.png
│   │           └── full_{HH-MM-SS}_{score}.png
│   ├── classified/                  # (Optional) Local classified storage
│   └── results.log                 # System logs
│
├── /var/www/html/                   # Web-accessible directory
│   ├── classified/                  # Classified images (served by Nginx)
│   │   └── {YYYY-MM-DD}/
│   │       └── {visitation_id}/
│   │           ├── boxed_{HH-MM-SS}_{score}_{species}_{class_score}.png
│   │           └── full_{HH-MM-SS}_{score}.png
│   ├── visitations.json             # Visitation metadata (generated)
│   └── [web/build/]                 # React frontend (deployed)
│
└── all_models/                      # AI model storage
    ├── ssd_mobilenet_v2_coco_quant_postprocess_edgetpu.tflite
    ├── mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite
    ├── coco_labels.txt
    └── inat_bird_labels.txt
```

### File Naming Conventions

#### Detection Phase
- **Boxed**: `boxed_{HH-MM-SS}_{detection_score}.png`
- **Full**: `full_{HH-MM-SS}_{detection_score}.png`

#### Classification Phase
- **Boxed**: `boxed_{HH-MM-SS}_{detection_score}_{species-name}_{classification_score}.png`
- **Full**: `full_{HH-MM-SS}_{detection_score}.png` (unchanged)

**Example:**
- Before: `boxed_14-30-25_85.png`
- After: `boxed_14-30-25_85_american-robin_92.png`

---

## Operational Phases

### Phase 1: Continuous Detection (Default State)

**Duration**: Continuous (24/7 when service is running)

**Components:**
- `leroy.service` (systemd)
- `leroy.py` (or hardware-specific variant)
- Detection model inference
- Visitation tracking
- Photo capture

**Activities:**
1. Capture frames from camera (2048x1536 resolution)
2. Resize for detection (500px width)
3. Run detection model inference
4. Track visitations (start/end, photo limits)
5. Capture boxed and full photos
6. Store in `storage/detected/`

**Performance Targets:**
- Frame rate: 4+ FPS
- Detection latency: <250ms per frame
- Memory usage: <500MB

### Phase 2: Classification (Scheduled)

**Duration**: Periodic (cron job, typically hourly or daily)

**Components:**
- `classify.sh` (cron script)
- `classify.py` (classification processing)
- Classification model inference

**Activities:**
1. Stop detection service
2. Process all images in `storage/detected/`
3. Run classification model on boxed images
4. Rename files with species and score
5. Move to `/var/www/html/classified/`
6. Restart detection service

**Performance Targets:**
- Classification latency: <100ms per image
- Batch processing: Handle 100+ images efficiently

### Phase 3: Visitation Processing (Scheduled)

**Duration**: Periodic (runs after classification)

**Components:**
- `visitation.py` (visitation analysis)
- JSON generation

**Activities:**
1. Group images by `visitation_id`
2. Calculate visitation metrics (duration, species, best photo)
3. Generate `visitations.json`
4. Update web interface data

**Performance Targets:**
- Processing time: <5 seconds for daily data
- JSON file size: Reasonable for web loading

---

## Integration with Raspberry Pi AI Kit

### Official Tools and SDKs

**Priority**: Always use Raspberry Pi's official tools and SDKs for AI Kit integration.

#### 1. rpicam-apps (Camera Pipeline)

Raspberry Pi's official camera applications have been updated to support AI Kit:

```bash
# Install rpicam-apps (includes AI Kit support)
sudo apt update
sudo apt install rpicam-apps
```

**Benefits:**
- Native camera integration
- Real-time AI processing in camera pipeline
- Optimized for Raspberry Pi hardware
- Official support and updates

#### 2. Hailo Dataflow Compiler (DFC)

Official tool for converting models to HEF (Hailo Executable Format):

```bash
# Install Hailo DFC (via Raspberry Pi repositories)
# Follow official Raspberry Pi AI Kit documentation
```

**Usage:**
- Convert TensorFlow Lite models to HEF format
- Optimize models for Hailo-8L accelerator
- Validate model compatibility

#### 3. Hailo Python SDK

Official Python SDK for Hailo AI Kit:

```python
# Official Hailo SDK (via Raspberry Pi)
from hailo_platform import Device, InferVStreams, InferModel

# Initialize device
device = Device()

# Load model (HEF format)
network_group = device.load_model('model.hef')

# Run inference
with InferVStreams(network_group) as infer_pipeline:
    results = infer_pipeline.infer(input_data)
```

**Key Points:**
- Use official SDK from Raspberry Pi repositories
- Follow Raspberry Pi's documentation and examples
- Prefer official tools over third-party alternatives

### Migration Strategy

1. **Use Official Tools First**
   - Install via Raspberry Pi's official repositories
   - Follow Raspberry Pi's AI Kit documentation
   - Use `rpicam-apps` for camera integration if possible

2. **Model Conversion**
   - Use Hailo DFC (official tool)
   - Convert models to HEF format
   - Validate accuracy after conversion

3. **API Integration**
   - Use official Hailo Python SDK
   - Follow Raspberry Pi's code examples
   - Maintain compatibility with existing code structure

4. **Testing**
   - Test on Raspberry Pi 5 + AI Kit hardware
   - Validate performance improvements
   - Ensure backward compatibility where possible

---

## System Dependencies

### System Dependencies

```bash
# Raspberry Pi official repositories
# (Follow official AI Kit installation guide)

# Packages (expected)
- rpicam-apps (with AI Kit support)
- hailo-platform (official SDK)
- hailo-dataflow-compiler (model conversion)
```

**Installation Priority:**
1. Follow Raspberry Pi's official AI Kit installation guide
2. Use official repositories and packages
3. Avoid third-party alternatives unless necessary

---

## Error Handling & Recovery

### Service Failures

**Detection Service (`leroy.service`):**
- **Restart Policy**: `Restart=on-abort`
- **Recovery**: Automatic restart on failure
- **Logging**: Systemd journal (`journalctl -u leroy.service`)

### Classification Failures

**Classification Script (`classify.sh`):**
- **Error Handling**: Script continues even if classification fails
- **Recovery**: Service restarts regardless of classification result
- **Logging**: Check `storage/results.log`

### Camera Failures

**Camera Disconnection:**
- **Detection**: OpenCV returns `None` for frames
- **Handling**: Log error, continue loop, attempt reconnection
- **Recovery**: Service restart may be needed

### Storage Failures

**Disk Space:**
- **Check**: `has_disk_space()` function in `photo.py`
- **Threshold**: 95% disk usage
- **Action**: Skip photo capture if disk full

---

## Performance Considerations

### Detection Phase

**Optimizations:**
- Frame resizing (2048x1536 → 500px width)
- Frame skipping if processing is slow
- Efficient NumPy operations
- Object pooling for repeated operations

### Classification Phase

**Optimizations:**
- Batch processing when possible
- Efficient file I/O (move vs copy)
- Parallel processing if supported

### Memory Management

**Constraints:**
- Pi 5: 4GB/8GB RAM (sufficient for batch processing)

**Best Practices:**
- Avoid storing full-resolution frames unnecessarily
- Release OpenCV resources promptly
- Monitor memory usage
- Use object pooling

---

## Security Considerations

### File Permissions

- **Service User**: `leroy` (non-root)
- **Storage**: User-writable directories
- **Web Directory**: `/var/www/html/` (www-data group)

### Network Security

- **SSH**: Key-based authentication
- **Web Interface**: Local network only (or HTTPS if exposed)
- **Firewall**: Restrict unnecessary ports

---

## Monitoring & Logging

### Log Locations

- **Service Logs**: `journalctl -u leroy.service`
- **Application Logs**: `storage/results.log`
- **System Logs**: `/var/log/syslog`

### Key Metrics

- **Detection Rate**: FPS, inference latency
- **Classification Rate**: Images processed per minute
- **Storage Usage**: Disk space, file counts
- **System Health**: CPU temperature, memory usage

---

## Visitation System

### Scientific Definition

**A "visitation"** in ornithological terms refers to:
> An observation period at a specific location and time during which one or more bird species are present.

**Key Points**:
- ✅ **Multiple species** can be part of a single visitation
- ✅ Defined by **time and location**, not by species
- ✅ Records **all species** observed during the period
- ✅ Follows eBird/iNaturalist scientific standards

### Visitation Data Structure

**Enhanced Format** (Scientific Standard):
```json
{
  "visitation_id": "uuid-abc123",
  "start_datetime": "2024-01-15 10:30:00",
  "end_datetime": "2024-01-15 10:45:00",
  "duration": 900,
  
  "species_observations": [
    {
      "common_name": "American Robin",
      "scientific_name": "Turdus migratorius",
      "count": 4,
      "first_seen": "2024-01-15 10:30:15",
      "last_seen": "2024-01-15 10:44:30",
      "confidence": 0.92,
      "photos": [...],
      "best_photo": "..."
    }
  ],
  
  "species_count": 2,
  "species": "American Robin",  // Backward compatible
  "best_photo": "...",
  "full_image": "..."
}
```

**Features**:
- ✅ Multiple species per visitation
- ✅ Scientific names (extracted from labels or "Unknown")
- ✅ Individual counts per species
- ✅ Temporal data (first_seen, last_seen)
- ✅ Backward compatible with single-species format

### Visitation Processing

**From `visitation.py`**:
1. Groups photos by `visitation_id`
2. Identifies all species in visitation (not just most common)
3. Creates `species_observations` array
4. Calculates counts, confidence, temporal data per species
5. Generates scientific-format JSON

---

## Social Media Integration

### Platform: Bluesky

**Implementation**: Optional posting to Bluesky (atproto)

**Configuration**:
- `BLUESKY_ENABLED`: Enable/disable posting
- `BLUESKY_HANDLE`: Bluesky handle
- `BLUESKY_APP_PASSWORD`: App password

**Posting Rules**:
- Maximum 3 posts per day
- Minimum 4 hours between posts
- Posting window: 8:00 AM - 8:00 PM
- Daily summary with "Image of the Day"
- Individual posts for special visitations (high confidence, multiple species)

**Error Handling**:
- Silently ignores if not authenticated
- Never crashes main detection service
- Logs errors for debugging

**See**: `@social-media-posting.mdc` for complete posting rules

---

## Future Enhancements

### Potential Improvements

1. **Real-time Classification**: Classify during detection (if hardware supports)
2. **Batch Processing**: Process multiple frames simultaneously
3. **Higher Resolution**: Leverage Pi 5's capabilities for 4K capture
4. **Multi-model Inference**: Run detection and classification in parallel
5. **Cloud Integration**: Sync to cloud storage automatically

---

**Reference**: This architecture document should be updated as the system evolves, especially during the migration to Raspberry Pi 5 + AI Kit.
